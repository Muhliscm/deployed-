{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6660,"status":"ok","timestamp":1673155262745,"user":{"displayName":"Muhlis Cm","userId":"14517940800396027435"},"user_tz":-330},"id":"g0qe8WyX3ffE","outputId":"d8d63fdd-3b31-4fdc-a34c-c47376155319"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting linkedin-jobs-scraper\n","  Downloading linkedin_jobs_scraper-4.0.0-py3-none-any.whl (28 kB)\n","Collecting selenium>=4.12.0\n","  Downloading selenium-4.17.2-py3-none-any.whl (9.9 MB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m208.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n","\u001b[?25hCollecting typing_extensions>=4.9.0\n","  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from selenium>=4.12.0->linkedin-jobs-scraper) (2022.12.7)\n","Collecting trio~=0.17\n","  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m180.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from selenium>=4.12.0->linkedin-jobs-scraper) (1.26.14)\n","Collecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n","Collecting sniffio>=1.3.0\n","  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: idna in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium>=4.12.0->linkedin-jobs-scraper) (3.4)\n","Collecting outcome\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: attrs>=20.1.0 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium>=4.12.0->linkedin-jobs-scraper) (22.1.0)\n","Collecting exceptiongroup\n","  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: sortedcontainers in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium>=4.12.0->linkedin-jobs-scraper) (2.4.0)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.12.0->linkedin-jobs-scraper) (1.7.1)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m154.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n","\u001b[?25hInstalling collected packages: typing_extensions, sniffio, outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium, linkedin-jobs-scraper\n","  Attempting uninstall: typing_extensions\n","    Found existing installation: typing_extensions 4.4.0\n","    Uninstalling typing_extensions-4.4.0:\n","      Successfully uninstalled typing_extensions-4.4.0\n","  Attempting uninstall: sniffio\n","    Found existing installation: sniffio 1.2.0\n","    Uninstalling sniffio-1.2.0:\n","      Successfully uninstalled sniffio-1.2.0\n","Successfully installed exceptiongroup-1.2.0 h11-0.14.0 linkedin-jobs-scraper-4.0.0 outcome-1.3.0.post0 selenium-4.17.2 sniffio-1.3.0 trio-0.24.0 trio-websocket-0.11.1 typing_extensions-4.9.0 wsproto-1.2.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# pip install linkedin-jobs-scraper"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"-d3ta_9UDvAR"},"outputs":[{"ename":"TypeError","evalue":"WebDriver.__init__() got multiple values for argument 'options'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/muhliscm/Desktop/data_engineering/data science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m chrome_options\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--no-sandbox\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m chrome_options\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--disable-dev-shm-usage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m wd \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(\u001b[39m'\u001b[39;49m\u001b[39mchromedriver\u001b[39;49m\u001b[39m'\u001b[39;49m,options\u001b[39m=\u001b[39;49mchrome_options)\n","\u001b[0;31mTypeError\u001b[0m: WebDriver.__init__() got multiple values for argument 'options'"]}],"source":["# !pip install selenium\n","# !apt-get update # to update ubuntu to correctly run apt install\n","# !apt install chromium-chromedriver\n","# !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n","from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","wd = webdriver.Chrome('chromedriver',options=chrome_options)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true},"id":"0x6KAT_qCL4n"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting webdriver-manager\n","  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: packaging in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from webdriver-manager) (22.0)\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from webdriver-manager) (2.28.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (2.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/muhliscm/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (1.26.14)\n","Installing collected packages: python-dotenv, webdriver-manager\n","Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# pip install webdriver-manager\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AZUeqGoqDI7Q"},"outputs":[],"source":["# !sudo apt-get install -y chromium-browser"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true},"id":"3ItTRbCPCgpp"},"outputs":[{"ename":"AttributeError","evalue":"'str' object has no attribute 'capabilities'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:38\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     path \u001b[39m=\u001b[39m SeleniumManager()\u001b[39m.\u001b[39;49mdriver_location(options) \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/common/selenium_manager.py:87\u001b[0m, in \u001b[0;36mSeleniumManager.driver_location\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m\"\"\"Determines the path of the correct driver.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[39m:Args:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m - browser: which browser to get the driver path for.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m:Returns: The driver path to use\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m browser \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39;49mcapabilities[\u001b[39m\"\u001b[39m\u001b[39mbrowserName\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     89\u001b[0m args \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_binary()), \u001b[39m\"\u001b[39m\u001b[39m--browser\u001b[39m\u001b[39m\"\u001b[39m, browser]\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m/home/muhliscm/Desktop/data_engineering/data science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m \u001b[39mimport\u001b[39;00m webdriver\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwebdriver_manager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchrome\u001b[39;00m \u001b[39mimport\u001b[39;00m ChromeDriverManager\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(ChromeDriverManager()\u001b[39m.\u001b[39;49minstall())\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[39m=\u001b[39m service \u001b[39mif\u001b[39;00m service \u001b[39melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[39m=\u001b[39m options \u001b[39mif\u001b[39;00m options \u001b[39melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     46\u001b[0m     browser_name\u001b[39m=\u001b[39;49mDesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m\"\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     47\u001b[0m     vendor_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     48\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m     49\u001b[0m     service\u001b[39m=\u001b[39;49mservice,\n\u001b[1;32m     50\u001b[0m     keep_alive\u001b[39m=\u001b[39;49mkeep_alive,\n\u001b[1;32m     51\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/chromium/webdriver.py:49\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m\"\"\"Creates a new WebDriver instance of the ChromiumDriver. Starts the\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mservice and then creates new WebDriver instance of ChromiumDriver.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m - keep_alive - Whether to configure ChromiumRemoteConnection to use HTTP keep-alive.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m service\n\u001b[0;32m---> 49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m DriverFinder\u001b[39m.\u001b[39;49mget_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice, options)\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     52\u001b[0m executor \u001b[39m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     53\u001b[0m     remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[1;32m     54\u001b[0m     browser_name\u001b[39m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     ignore_proxy\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     58\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:40\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     38\u001b[0m     path \u001b[39m=\u001b[39m SeleniumManager()\u001b[39m.\u001b[39mdriver_location(options) \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m---> 40\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to obtain driver for \u001b[39m\u001b[39m{\u001b[39;00moptions\u001b[39m.\u001b[39mcapabilities[\u001b[39m'\u001b[39m\u001b[39mbrowserName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m using Selenium Manager.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m Path(path)\u001b[39m.\u001b[39mis_file():\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'"]}],"source":["from selenium import webdriver\n","from webdriver_manager.chrome import ChromeDriverManager\n","\n","driver = webdriver.Chrome(ChromeDriverManager().install())"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"id":"DEhJbet7xFPN"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"]}],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"background_save":true},"id":"gleVB0Jy3jdY"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:li:scraper:('Using strategy AnonymousStrategy',)\n","WARNING:li:scraper:(\"AnonymousStrategy is no longer maintained and it won't probably work. It is recommended to use an authenticated session, see documentation at https://github.com/spinlud/py-linkedin-jobs-scraper#anonymous-vs-authenticated-session.\",)\n"]}],"source":["import logging\n","from linkedin_jobs_scraper import LinkedinScraper\n","from linkedin_jobs_scraper.events import Events, EventData, EventMetrics\n","from linkedin_jobs_scraper.query import Query, QueryOptions, QueryFilters\n","from linkedin_jobs_scraper.filters import RelevanceFilters, TimeFilters, TypeFilters, ExperienceLevelFilters, \\\n","    OnSiteOrRemoteFilters\n","\n","# Change root logger level (default is WARN)\n","logging.basicConfig(level=logging.INFO)\n","\n","data_list = []\n","# Fired once for each successfully processed job\n","def on_data(data: EventData):\n","    data_list.append({\"Job_Title\":data.title, \"Comapny Name\":data.company, \"Posted_date\":data.date, \"Job_Link\":data.link, \"Job_Description\":data.description})\n","    # print('>>>>>>>>>>>>>>>>>>>',data.description)\n","    \n","    \n","\n","\n","# Fired once for each page (25 jobs)\n","def on_metrics(metrics: EventMetrics):\n","    print('[ON_METRICS]', str(metrics))\n","\n","\n","def on_error(error):\n","    print('[ON_ERROR]', error)\n","\n","\n","def on_end():\n","    print('[ON_END]')\n","    df = pd.DataFrame.from_dict(data_list)\n","    return df\n","    \n","\n","\n","\n","scraper = LinkedinScraper(\n","    chrome_executable_path=None,  # Custom Chrome executable path (e.g. /foo/bar/bin/chromedriver) \n","    chrome_options=None,  # Custom Chrome options here\n","    headless=True,  # Overrides headless mode only if chrome_options is None\n","    max_workers=1,  # How many threads will be spawned to run queries concurrently (one Chrome driver for each thread)\n","    slow_mo=3,  # Slow down the scraper to avoid 'Too many requests 429' errors (in seconds)\n","    page_load_timeout=100  # Page load timeout (in seconds)    \n",")\n","\n","# Add event listeners\n","scraper.on(Events.DATA, on_data)\n","scraper.on(Events.ERROR, on_error)\n","scraper.on(Events.END, on_end)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true},"id":"KsOfY3c04eY7"},"outputs":[],"source":["queries = [\n","    Query(\n","        query='Data Scientist',\n","        options=QueryOptions(\n","            locations=['India'],\n","            apply_link=True,  # Try to extract apply link (easy applies are skipped). If set to True, scraping is slower because an additional page mus be navigated. Default to False.\n","            skip_promoted_jobs=True,  # Skip promoted jobs. Default to False.\n","            limit=25,\n","            filters=QueryFilters(\n","                relevance=RelevanceFilters.RECENT,\n","                time=TimeFilters.MONTH,\n","                type=[TypeFilters.FULL_TIME, TypeFilters.INTERNSHIP],\n","                on_site_or_remote=[OnSiteOrRemoteFilters.REMOTE],\n","                experience=[ExperienceLevelFilters.MID_SENIOR]\n","            )\n","        )\n","    ),\n","]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true},"id":"-uNftZLrNYlA"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:li:scraper:('Starting new query', \"Query(query=Data Scientist options=QueryOptions(limit=25 locations=['India'] filters=QueryFilters(relevance=RelevanceFilters.RECENT time=TimeFilters.MONTH type=[<TypeFilters.FULL_TIME: 'F'>, <TypeFilters.INTERNSHIP: 'I'>] experience=[<ExperienceLevelFilters.MID_SENIOR: '4'>] on_site_or_remote=[<OnSiteOrRemoteFilters.REMOTE: '2'>]) apply_link=True skip_promoted_jobs=True page_offset=0))\")\n","INFO:li:scraper:('Chrome debugger url', 'http://localhost:44839')\n","INFO:li:scraper:('Websocket debugger url: ', 'ws://localhost:44839/devtools/page/0B5E5A2E8E653A3B06479D629634F4C7')\n","WARNING:li:scraper:('[AnonymousStrategy]', 'This run strategy is no longer supported')\n","INFO:li:scraper:('[Data Scientist][India]', 'Opening https://www.linkedin.com/jobs/search?keywords=Data+Scientist&location=India&sortBy=DD&f_TPR=r2592000&f_JT=F%2CI&f_E=4&start=0')\n","INFO:li:scraper:('[Data Scientist][India]', 'Trying first selectors set')\n","INFO:li:scraper:('[Data Scientist][India]', 'Trying second selectors set')\n","INFO:li:scraper:('[Data Scientist][India]', 'OK')\n","INFO:li:scraper:('[Data Scientist][India]', 'Starting pagination loop')\n","INFO:li:scraper:('[Data Scientist][India]', 'Found 25 jobs')\n","INFO:li:scraper:('[Data Scientist][India][1]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][2]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][3]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][4]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][5]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][6]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][7]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][8]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][9]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][10]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][11]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][12]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][13]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][14]', 'Processed')\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","ERROR:li:scraper:('[Data Scientist][India][15]', 'Timeout on loading job details')\n","NoneType: None\n","INFO:li:scraper:('[Data Scientist][India][15]', 'Checking for new jobs to load...')\n","INFO:li:scraper:('[Data Scientist][India][15]', 'Found 50 jobs')\n","INFO:li:scraper:('[Data Scientist][India][15]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][16]', 'Processed')\n","ERROR:li:scraper:('[Data Scientist][India][17]', 'Timeout on loading job details')\n","NoneType: None\n","INFO:li:scraper:('[Data Scientist][India][17]', 'Processed')\n","ERROR:li:scraper:('[Data Scientist][India][18]', 'Timeout on loading job details')\n","NoneType: None\n","INFO:li:scraper:('[Data Scientist][India][18]', 'Processed')\n","ERROR:li:scraper:('[Data Scientist][India][19]', 'Timeout on loading job details')\n","NoneType: None\n","INFO:li:scraper:('[Data Scientist][India][19]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][20]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][21]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][22]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][23]', 'Processed')\n","INFO:li:scraper:('[Data Scientist][India][24]', 'Processed')\n","ERROR:li:scraper:('[Data Scientist][India][25]', 'Timeout on loading job details')\n","NoneType: None\n","INFO:li:scraper:('[Data Scientist][India][25]', 'Processed')\n"]},{"name":"stdout","output_type":"stream","text":["[ON_END]\n"]}],"source":["scraper.run(queries)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZfWejPAjNhbV"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true},"id":"5_hQw6tzxwwj"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ON_END]\n"]}],"source":["data_set = on_end()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"background_save":true},"id":"KDAs1OQxw4Nv"},"outputs":[],"source":["df = data_set.copy(deep=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"background_save":true},"id":"SB-vIKYsk2sJ"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Job_Title</th>\n","      <th>Comapny Name</th>\n","      <th>Posted_date</th>\n","      <th>Job_Link</th>\n","      <th>Job_Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AI/ML Python with Utilities</td>\n","      <td>eCosmos</td>\n","      <td>2024-01-25</td>\n","      <td>https://in.linkedin.com/jobs/view/ai-ml-python...</td>\n","      <td>Location: Bengaluru\\n\\nUS Shift: 5pm to 2am\\n\\...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Data Scientist</td>\n","      <td>Acme Services</td>\n","      <td>2024-01-29</td>\n","      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n","      <td>Job Description\\n\\n\\nSearch analysis and impro...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Machine Learning Engineer</td>\n","      <td>H2O.ai</td>\n","      <td>2024-01-16</td>\n","      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n","      <td>About This Opportunity\\n\\nWe are seeking a hig...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AI/ML Engineer</td>\n","      <td>K-RY Tech Advisory</td>\n","      <td>2024-01-24</td>\n","      <td>https://in.linkedin.com/jobs/view/ai-ml-engine...</td>\n","      <td>Job Summary\\n\\nWe are seeking a highly skilled...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Machine Learning Engineer</td>\n","      <td>Opendoor</td>\n","      <td>2024-01-21</td>\n","      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n","      <td>About Opendoor\\n\\nFounded in 2014, Opendoor’s ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Job_Title        Comapny Name Posted_date  \\\n","0  AI/ML Python with Utilities             eCosmos  2024-01-25   \n","1               Data Scientist       Acme Services  2024-01-29   \n","2    Machine Learning Engineer              H2O.ai  2024-01-16   \n","3               AI/ML Engineer  K-RY Tech Advisory  2024-01-24   \n","4    Machine Learning Engineer            Opendoor  2024-01-21   \n","\n","                                            Job_Link  \\\n","0  https://in.linkedin.com/jobs/view/ai-ml-python...   \n","1  https://in.linkedin.com/jobs/view/data-scienti...   \n","2  https://in.linkedin.com/jobs/view/machine-lear...   \n","3  https://in.linkedin.com/jobs/view/ai-ml-engine...   \n","4  https://in.linkedin.com/jobs/view/machine-lear...   \n","\n","                                     Job_Description  \n","0  Location: Bengaluru\\n\\nUS Shift: 5pm to 2am\\n\\...  \n","1  Job Description\\n\\n\\nSearch analysis and impro...  \n","2  About This Opportunity\\n\\nWe are seeking a hig...  \n","3  Job Summary\\n\\nWe are seeking a highly skilled...  \n","4  About Opendoor\\n\\nFounded in 2014, Opendoor’s ...  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"background_save":true},"id":"dyTWdHPRnmUn"},"outputs":[],"source":["df['Job_Description'] = df['Job_Description'].str.replace('\\n\\n',\" \").replace('\\n',\" \")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"background_save":true},"id":"8EyBq20Zqoet"},"outputs":[],"source":["df['Job_Description'] = df['Job_Description'].str.replace('\\n',\" \")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["df.to_csv(\"data_science_jobs.csv\",index=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"background_save":true},"id":"u9lrEFmrn3By"},"outputs":[],"source":["df['Job_Description'] = df['Job_Description'].str.lower()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true},"id":"_1mblDHQpUdn"},"outputs":[],"source":["import re\n","def remove_html_tags(text):\n","    pattern = re.compile('<.*?>')\n","    return pattern.sub(r'', text)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"background_save":true},"id":"B4Ku8TLepWeI"},"outputs":[],"source":["df['Job_Description'] = df['Job_Description'].apply(remove_html_tags)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"background_save":true},"id":"IH7JYj3qpewH"},"outputs":[],"source":["def remove_url(text):\n","    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return pattern.sub(r'', text)\n","df['Job_Description'] = df['Job_Description'].apply(remove_url)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"background_save":true},"id":"HzxeTlthp1e0"},"outputs":[],"source":["import string\n","excluded = string.punctuation\n","def remove_punc(text):\n","    return text.translate(str.maketrans('', '', excluded))\n","df['Job_Description'] = df['Job_Description'].apply(remove_punc)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"background_save":true},"id":"axsbI05EwMIA"},"outputs":[{"data":{"text/plain":["'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["excluded"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"background_save":true},"id":"_xbq-1bLqMiI"},"outputs":[{"data":{"text/plain":["0     location bengaluru us shift 5pm to 2am about t...\n","1     job description  search analysis and improveme...\n","2     about this opportunity we are seeking a highly...\n","3     job summary we are seeking a highly skilled an...\n","4     about opendoor founded in 2014 opendoor’s miss...\n","5     job summary we are seeking a highly skilled an...\n","6     job summary we are seeking a highly skilled an...\n","7     job summary we are seeking a highly skilled an...\n","8     job summary we are seeking a highly skilled an...\n","9     job summary we are seeking a highly skilled an...\n","10    job summary we are seeking a highly skilled an...\n","11    description data scientist role and responsibi...\n","12    job description m l engineer exp 5 yrs loc pan...\n","13    locationhyderabad notice perioed serving upto ...\n","14    company description when you’re one of us you ...\n","15    job description we are seeking highly skilled ...\n","16    optimum data analytics is hiring aiml python d...\n","17    client  gain well pay roll quess corp gainwell...\n","18    senior data scientist rd – functional material...\n","19    your responsibilities includes but not limited...\n","20    fynd is india’s largest omnichannel platform a...\n","21    we are hiring avp data analytics for a financi...\n","22    ltimindtree is a global technology consulting ...\n","23    company description when you’re one of us you ...\n","24    greeting from getronics   we have interesting ...\n","Name: Job_Description, dtype: object"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df['Job_Description']"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"background_save":true},"id":"BOjx-AN5qO0K"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/muhliscm/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","def remove_stopwords(text):\n","    new_text = []\n","    \n","    for word in text.split():\n","        if word in stopwords.words('english'):\n","            new_text.append('')\n","        else:\n","            new_text.append(word)\n","    x = new_text[:]\n","    new_text.clear()\n","    return \" \".join(x)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Txa2nuNTqhYG"},"outputs":[],"source":["df['Job_Description'] = df['Job_Description'].apply(remove_stopwords)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"75RDkNNert84"},"outputs":[{"data":{"text/plain":["0     job description 1 conduct indepth analysis  la...\n","1     company description nykaa   digitally native c...\n","2     project role data scientist management level g...\n","3     location bengaluru us shift 5pm  2am   company...\n","4     we’re looking   mlmlops engineering specialist...\n","5       role   looking   highly capable machine lear...\n","6     data scientist iisr data scientist life  media...\n","7      acceldata acceldata   enterprise data observa...\n","8     job description designation solution developer...\n","9     finacle   flagship banking product  infosys   ...\n","10     excitel  started  journey  2015   singular mi...\n","11    data scientist location bangalore experience r...\n","12    specialization handson work     following tool...\n","13    position – data scientist location gurgaon exp...\n","14     intellect design arena ltd intellect design a...\n","15    inviting applications   role  manager data sci...\n","16    cashfree   leading payments  api banking solut...\n","17    role data scientist job location bangalore pun...\n","18     balancehero balancehero korea   company  deve...\n","19    coursera  launched  2012  two stanford compute...\n","20    razorpay  founded  shashank kumar  harshil mat...\n","21    cloud native data  aiml skills  experience lik...\n","22    designation data scientist experience 5 years ...\n","23    ● analyse  integrate data  multiple sources  e...\n","24      opportunity   seeking  highly skilled  motiv...\n","Name: Job_Description, dtype: object"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df['Job_Description']"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"BxQ1GxwysL5-"},"outputs":[],"source":["import re\n","def remove_emoji(text):\n","    emoji_pattern = re.compile(\"[\"\n","                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                           u\"\\U00002702-\\U000027B0\"\n","                           u\"\\U000024C2-\\U0001F251\"\n","                           \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"OElgzmXdye3R"},"outputs":[],"source":["df['Job_Description'] = df['Job_Description'].apply(remove_emoji)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"jdoCHE2Fy31e"},"outputs":[{"ename":"TypeError","evalue":"unhashable type: 'Series'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/muhliscm/Desktop/data_engineering/data science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/muhliscm/Desktop/data_engineering/data%20science/dsProjects/Linked_In_Skill_Extractor/api_test.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mJob_Description\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mreplace(df[\u001b[39m\"\u001b[39;49m\u001b[39mComapny Name\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mlower(),\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/strings/accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/strings/accessor.py:1500\u001b[0m, in \u001b[0;36mStringMethods.replace\u001b[0;34m(self, pat, repl, n, case, flags, regex)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[39mif\u001b[39;00m case \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1498\u001b[0m     case \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1500\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39;49m_str_replace(\n\u001b[1;32m   1501\u001b[0m     pat, repl, n\u001b[39m=\u001b[39;49mn, case\u001b[39m=\u001b[39;49mcase, flags\u001b[39m=\u001b[39;49mflags, regex\u001b[39m=\u001b[39;49mregex\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1503\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/strings/object_array.py:158\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_replace\u001b[0;34m(self, pat, repl, n, case, flags, regex)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m regex \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m         pat \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mescape(pat)\n\u001b[0;32m--> 158\u001b[0m     pat \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49mcompile(pat, flags\u001b[39m=\u001b[39;49mflags)\n\u001b[1;32m    160\u001b[0m n \u001b[39m=\u001b[39m n \u001b[39mif\u001b[39;00m n \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    161\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: pat\u001b[39m.\u001b[39msub(repl\u001b[39m=\u001b[39mrepl, string\u001b[39m=\u001b[39mx, count\u001b[39m=\u001b[39mn)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/re.py:251\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(pattern, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/re.py:293\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    291\u001b[0m     flags \u001b[39m=\u001b[39m flags\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    292\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m _cache[\u001b[39mtype\u001b[39;49m(pattern), pattern, flags]\n\u001b[1;32m    294\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[39mpass\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"]}],"source":["df['Job_Description'].str.replace(df[\"Comapny Name\"].str.lower(),\"\")"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"s5eCOL2ny6fe"},"outputs":[{"data":{"text/plain":["0                  samsung india\n","1                          nykaa\n","2                          iqvia\n","3                        ecosmos\n","4                    ltimindtree\n","5                  indusind bank\n","6                      media.net\n","7                      acceldata\n","8              tata technologies\n","9                infosys finacle\n","10             excitel broadband\n","11                     tietoevry\n","12                       philips\n","13                           exl\n","14    intellect design arena ltd\n","15                       genpact\n","16             cashfree payments\n","17     tata consultancy services\n","18             balancehero india\n","19                      coursera\n","20                      razorpay\n","21                   ltimindtree\n","22                     valuelabs\n","23            vayuz technologies\n","24                        h2o.ai\n","Name: Comapny Name, dtype: object"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Comapny Name\"].str.lower()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM6DcSsRz9WM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNpnT5dit159RK+yeM/aNGV","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
