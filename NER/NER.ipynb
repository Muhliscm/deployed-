{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets seqeval"
      ],
      "metadata": {
        "id": "NdSPEnsr1VmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181c7d0e-2a3c-4950-9b69-ddd58fa66076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We0DP5IN1V25",
        "outputId": "647ace99-a3bf-443f-eed3-73d02774226d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsU1nss2jvh8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"conll2003\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcXK9khQTK-N",
        "outputId": "0f3df427-e20b-4c4d-c924-31a34b75d00d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efOrlPCCTO6l",
        "outputId": "2cebaffe-67a9-47fb-83c7-442e302df133"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "raw_datasets[\"train\"][0][\"tokens\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N74N5EbxTTIP",
        "outputId": "98836928-8035-420f-ba84-b203eee4e1e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "raw_datasets[\"train\"][0][\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFbc5r1WTWDo",
        "outputId": "ba367455-3ddf-4873-9dc8-072f2735cb00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
        "ner_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiu1RBM8TYvO",
        "outputId": "09e46ffb-fbff-4796-e882-cdea897914c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "label_names = ner_feature.feature.names\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvN1ZyieTasK",
        "outputId": "98eba40a-73a3-4a7e-a90e-d17a6e68635a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU    rejects German call to boycott British lamb . \n",
            "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
          ]
        }
      ],
      "source": [
        "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = label_names[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kmLem_2Tgqb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nybdyedSTlb2",
        "outputId": "91a69476-6fae-4d9e-850a-317a4b368efa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.save_pretrained('/content/drive/MyDrive/NER_Bert')"
      ],
      "metadata": {
        "id": "UYo6MGBzKNXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO83LbJ4ToFZ",
        "outputId": "174ce15c-5a6d-4f0a-baa4-e48773f087bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOucwPYMTtFj",
        "outputId": "daa3a1d7-915d-4284-cfea-af4bd185a33e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "inputs.word_ids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIHleztMTyla"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaW8p3NET2eu",
        "outputId": "d62d7b60-2215-4555-f8a9-919c525b944a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
          ]
        }
      ],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p3U8jHeT6oh"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fe0cc9630bfd4c9c9b0755859c6929fc",
            "22c7c48773f84b1a9a5383351292f233",
            "e7efe94055464d50a6eb9de632135e33",
            "25a1b05d8c01455d81c59bb5a18252fe",
            "1d0b348c6c154443aec0920d755c816e",
            "e86680c8c4024c4aa97645033d5ef87d",
            "6d8e9fd4d90b4c90815ae1a5f4705451",
            "749be6a68f464b80849d1e7454d9944f",
            "a6f47a3aaa3f4962b71c84ce1a85b268",
            "793d69d97cf7455d8594e5294fd8b061",
            "93d2f84fc3e54ef58624870916f89f67"
          ]
        },
        "id": "UFMYsfIOT-ko",
        "outputId": "0fc84564-2f2f-403b-888f-b6b317d5e3d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe0cc9630bfd4c9c9b0755859c6929fc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapO3LdzBws6",
        "outputId": "20b12d6c-f2be-4777-d4fe-92a04918b06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['test'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdhpdPenB4Yb",
        "outputId": "dbb1470c-1449-4e91-8896-bc17f9c528e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101,\n",
              "  156,\n",
              "  9244,\n",
              "  10954,\n",
              "  2069,\n",
              "  118,\n",
              "  147,\n",
              "  12240,\n",
              "  14962,\n",
              "  25075,\n",
              "  1942,\n",
              "  149,\n",
              "  21986,\n",
              "  2428,\n",
              "  3663,\n",
              "  160,\n",
              "  11607,\n",
              "  117,\n",
              "  24890,\n",
              "  11607,\n",
              "  1592,\n",
              "  15969,\n",
              "  156,\n",
              "  19556,\n",
              "  22861,\n",
              "  6258,\n",
              "  2036,\n",
              "  18581,\n",
              "  2271,\n",
              "  12420,\n",
              "  1942,\n",
              "  119,\n",
              "  102],\n",
              " 'token_type_ids': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " 'labels': [-100,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  -100]}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQAQwX-BUDp2"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwN0p4eaUIGE",
        "outputId": "d97c9dc6-6964-435d-ae13-35e0c5eaa5f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 12), dtype=int64, numpy=\n",
              "array([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0,\n",
              "        -100],\n",
              "       [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100]])>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if5Vxw4BUMgo",
        "outputId": "ff8a8c57-c9d0-416c-bc8b-3490be92baa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
            "[-100, 1, 2, -100]\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x7hyMoYUSsA"
      },
      "outputs": [],
      "source": [
        "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcDaiwnvCOaG",
        "outputId": "eef7e46e-65dd-4486-d846-fa326abcd5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec={'input_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tf_train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWNMe1cwIfXc",
        "outputId": "d078e8cb-569f-4a1c-9c81-1c337e3d2249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(16, 57), dtype=int64, numpy=\n",
            "array([[  101,  2123,  1489,  9784,  1765,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1130,  1901,  1106,  1606, 11438,  4196,   117,  1103,\n",
            "        23195,  1209,  1145,  1138,  1106,  1129,  6228,   117,  1250,\n",
            "         1218,  1107,   170,  1264,   117,  1129,  7246,  1106,  8132,\n",
            "         2993,  1105,  1383, 18222,  2513,   119,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   156, 22705, 17818,  1104,  1103,  3129,  2058,  3016,\n",
            "         2082, 15540,  1348,   163,  6639, 11819,  1162, 14382, 13411,\n",
            "         4092,   170,  1512,   118,  1550,   118,   195,  7841,  1183,\n",
            "          117,  1421,   118,  1214, 28086,  2486,  1114,   170, 14247,\n",
            "         2860,  1104,  1620,   195,  7841,  6834,  1296,   117,  1103,\n",
            "         1419,   112,   188, 15465,  1163,  1113,  6356,   119,   102,\n",
            "            0,     0,     0],\n",
            "       [  101,   107, 22686,  1144,  1694,   170,  2503,  2261,  1107,\n",
            "         1115,  1700,   117,   107,  1163,  1847, 27093,   117,   170,\n",
            "        12256,  2618,  1120, 27900, 26531,   117,   139,  1663,  8495,\n",
            "         1105, 16692,   117,  1134,  8701,  1198,  1223,   109,   122,\n",
            "         3775,  1107,  4265, 17901,  1105, 10150,   119,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  4498, 14255,  8702, 26996,  3052,  2526,  1111,   107,\n",
            "         6340, 11507,   107,  3342,   119,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  5486,  5691,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  5096,  5765,  1200,   123,   121,   122,   122,   122,\n",
            "          125,   122,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 26660, 10719, 17656,  9984,  1820,   118,  4775,   118,\n",
            "         1659,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 23676,   149,  2346, 22054,  1708,  5691,  3324,   119,\n",
            "         4062,  1580,   123,   122,   120,   123,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   107,  1188,  4006,  1110,  1696,  1272,  1141,  1104,\n",
            "         1103, 19609,  1116,  1253,  2515, 15804,  1105,  3881,  1215,\n",
            "         1107,  1103,  7472,  1104, 23993,  9745,  1116,  1105,  1103,\n",
            "         7472,  1104,  1103,  1107, 13053,  8515,  1105,  1155,  1103,\n",
            "         1614,  1134,  1127,  1107,  1103, 19421,  1104,   170,  1825,\n",
            "         1195,  1138,  1136,  3626,  1870,   117,   107, 21862,  1324,\n",
            "         1163,   119,   102],\n",
            "       [  101,  1124,  1163,  1925, 11608,  1116,  1107, 23248,  1127,\n",
            "         1684,  1114,  1103,  2264,  2336,  1749,  1107,  2359, 10299,\n",
            "         1105,  1114,   158,   119,   156,   119,  1105,  2169, 11608,\n",
            "         1116,  1107,  1103,  1805,  1106,  1494,  1714,  1103, 12799,\n",
            "          119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   146,  8223,  7174,  1181, 10857, 11745, 11796,  1104,\n",
            "         1735,  7069,  1105,  2199,  2603,  6665,  1431, 19428, 22279,\n",
            "         1162,  1213,  1954,  3001,  1235,  1346,  1397,  1989,  1170,\n",
            "         4058,  1196,  1105,  1170,  1142,  1989,   112,   188,  1528,\n",
            "          118,  1521,  2195,  1107,  2199,  5600,   117, 14552,  1163,\n",
            "          119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  6652,  8121,  1107,  2290,  1113,  1285,  1104,  1231,\n",
            "          118,  6294,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1335,  9957,   131,  5327, 22589,   118,   124,   113,\n",
            "          141,   119, 18196,  3324,   117,   150,   119,  4575,  4589,\n",
            "          117,   140,   119, 26638,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 20018, 10522,  9888,  7842,  1126,  9334,  1730,  5438,\n",
            "         1106, 14812,  2692, 11907,  1197, 22235,  6592,  1107,  1103,\n",
            "         2223,  2517,  1170,   170,   171, 17897,  1200,  1121, 22824,\n",
            "         1116, 10159,  2893,   118,  7695, 11896,  3842,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   131,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(16, 57), dtype=int64, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(16, 57), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'labels': <tf.Tensor: shape=(16, 57), dtype=int64, numpy=\n",
            "array([[-100,    3,    0,    3,    0, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    7,    0,    0,    3,    4,\n",
            "           4,    4,    4,    4,    4,    4,    4,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    1,    2,    0,    0,    0,    0,    0,    3,\n",
            "           4,    4,    4,    4,    4,    4,    4,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    5,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    3,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    3,    4,    4,    4,    4,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    1,    2,    0,\n",
            "           0, -100],\n",
            "       [-100,    0,    0,    7,    0,    0,    0,    5,    0,    0,    0,\n",
            "           0,    7,    8,    0,    0,    0,    5,    0,    0,    5,    6,\n",
            "           6,    6,    0,    7,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    7,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    7,    8,    8,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    1,    0,    0,    5,    0,    0,    0,    0,    0,    0,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0,    5,    0,    3,    0,    0,    0,    0,    1,    2,\n",
            "           2,    0,    0,    1,    2,    2,    0,    0,    1,    2,    2,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    3,    4,    4,    0,    0,    0,    0,    0,    0,    1,\n",
            "           2,    2,    2,    2,    2,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    4,    0,    1,    2,    2,    2,\n",
            "           2,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100],\n",
            "       [-100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tf_eval_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS4QONFvIwxP",
        "outputId": "f423b132-7710-43dd-f4e4-a420d8c39d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[  101, 15531,  9741, 22441,  1942,   118,   149, 27514, 10954,\n",
            "         9272,  9637,  1708,  3048, 18172,  2036,   157,  1592, 22441,\n",
            "          152, 17145,  2069, 13020, 16972,  2101,   138, 26321,  9637,\n",
            "        15969, 27451, 11780,  1708,  7118, 16647,  9565,  3663,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   149, 11414,  2137, 11414,  1820,   118,  4775,   118,\n",
            "         1476,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1537,  1890,  1155,   118,  1668,  1200,  5676, 14068,\n",
            "         1261,  1300,  1111,  3383,  1113,  5286,  1112, 21854,  3222,\n",
            "         8860,  1118,  1126,  6687,  1105,  3614,  2326,  1107,  1160,\n",
            "         1552,  1106,  1321,  1166,  1120,  1103,  1246,  1104,  1103,\n",
            "         2514,  2899,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  2397,  2215,  1113,  1499,   117,  1463,   117,  1336,\n",
            "         1129,  1603,   118,  2077,  1112,  1641,  9521,  8493,   117,\n",
            "        15964,  1105,  9757,  1155,  1804,  1107,  1113,  2681,  1229,\n",
            "         5327,  1189,  1146,  1111,  1575,  1159,  1107,  1147,  4458,\n",
            "          118,  4634,  1801,  1222, 21942,   119,   102,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1258, 11518,  8860,  1149,  1111,  6032,  1113,  1103,\n",
            "         2280,  2106,  1120,  4378,  1914,   117, 21854,  2925,  1147,\n",
            "         1148,  6687,  1118,  5706,  2326,  1196,  1217, 21663,  1149,\n",
            "         1111,  1853,  1545,  1114,  1652,  6187,  2881,  4827,   140,\n",
            "         3556, 25699,  1781,  1210,  1111,  6032,   119,   102,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  6938,  1158,  1118, 21640,   117,  8860,  1400,   170,\n",
            "         4600,  1838,  1106,  1147,  1248,  6687,  1196, 14068,  2843,\n",
            "         1107,  1106, 15119,  1172,  1149,  1111, 21223,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  8493,   117,  1649,   117,  1440,  2218,  1106, 12699,\n",
            "         1147,  1499,  3205,  1170, 11896, 14607, 21984,  1105,  1943,\n",
            "         5723,  1522,  1172,   170,  3016,  5688,  1113,  1147,  1801,\n",
            "         1222,  6426,  1120,  3763,  1158,  1926,   119,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 21984,   117,  1737, 17317,  1106,  1652,   112,   188,\n",
            "         1141,   118,  1285,  5420,   117,  4168, 18960,   117,  1117,\n",
            "         1148,  2899,  1432,  1104,  1103,  1265,   117,  1112,  8493,\n",
            "         1680,  3413,  1477,  1105,  1261,   170,  1148,  6687,  1730,\n",
            "         1104,  5787,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1650,  1103,  1601,  6426,  1125,  1454,  1115,  1154,\n",
            "          170,  3413,   118,  1576,  4316,  1133,  1228,   118,  6898,\n",
            "         2511,  5723,  1125,   188, 12734, 16271,  1147,  7816,   117,\n",
            "         1781,  1300,  1111,  1572,  1107,  3615,  7318,  1105,  2128,\n",
            "         1172,  5205,  1113, 13606,  1111,  1421,  1105, 16252,  1111,\n",
            "         4458,   119,   102],\n",
            "       [  101,  1335,  1103, 16103,   117,  9757,  3495,  2929,  3726,\n",
            "          117,  1330,  1299, 14632,  1118,  1652,   117,  1598,  1106,\n",
            "         3747,  1117,  4217,  1112,  1119,  1723,  1117,  1300,  1111,\n",
            "         2532,  1113,  9170,  1114,  2908,  1136,  1149,  1113,  5286,\n",
            "         1107,  1103,  1801,  1222, 19876,   119,   102,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1124,  1108,  1218,  5534,  1118,  1652, 19953,  2392,\n",
            "        25991,  1150,  1189,  3102,  1112,  9757,  1804,  1113,  3565,\n",
            "         1580,  1111,  1978,   117,   170,  1730,  1104, 24354,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 15964,  2023,  1146,  1103,  8263,  1111,  1147,  1148,\n",
            "         2899,  1641,  1290,  3419,  1118,  7914, 22067,  1106, 15118,\n",
            "         1111,  1421,  1107,  1147,  1248,  6687,   117,  1253,  1620,\n",
            "         2326,  1283,  1121, 10101,  1126,  6687,  3326,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1925,  2545, 17820,  1261,  1565,  1111,  5787,  1133,\n",
            "         2929,  5234,   117, 13414,   117,  1105,  4446,   152,   112,\n",
            "         3414,  7990,   117, 11523,   117,  1261, 15964,  1106,  3862,\n",
            "         1475,  1105,   170,  1148,  6687,  1730,  1104, 24482,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1258,  1103,  9074,  1104,  3195,  1103,  2280,  1285,\n",
            "         1104,  1147,  1801,  6118,  4634,  1118,  1103,  4250,   117,\n",
            "         5327,  2843,  1146,   170,  6990,  1106, 21728, 21942,  1111,\n",
            "        21692,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1220,  1127,  1316,  1146,  1118,   170,   176,  7729,\n",
            "         2340,  5731,  1121,  1795,  2921,  1133,  4252,   118,  1652,\n",
            "         2698, 17124,  2405,   150,  1665,  1658, 26169,  1261,  1300,\n",
            "         1111,  3731,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1650,   188,  8928,  3491,  5327,  1125,  1680, 10601,\n",
            "         1111,  1210,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]])>, 'labels': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[-100,    0,    0,    0,    0,    0,    3,    4,    4,    4,    4,\n",
            "           4,    4,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    7,    8,    0,    0,    0,    0,    1,    2,    0,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    3,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    3,    0,    3,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    5,    6,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    5,    0,\n",
            "           0,    1,    2,    2,    2,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    3,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    2,    2,    0,    1,    2,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    3,    0,    5,    6,    6,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    1,    0,    0,    0,    0,    5,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100],\n",
            "       [-100,    0,    0,    5,    0,    3,    0,    1,    2,    0,    0,\n",
            "           0,    0,    0,    5,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    5,    0,    1,    2,    0,\n",
            "           0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    7,    1,    2,    0,    0,    0,    0,    0,    1,    2,\n",
            "           0,    0,    0,    0,    1,    2,    2,    2,    2,    0,    0,\n",
            "           0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0,    0,    0,\n",
            "           0,    0,    0,    3,    0,    0,    0, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    1,    2,    0,    7,    8,    8,    0,    0,    1,    2,\n",
            "           2,    2,    2,    0,    0,    0,    0,    0, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TbWTILIUYEM"
      },
      "outputs": [],
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l103uP-MJBoy",
        "outputId": "bb334384-8b3b-44a1-a3b8-430a96f851be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-PER',\n",
              " 2: 'I-PER',\n",
              " 3: 'B-ORG',\n",
              " 4: 'I-ORG',\n",
              " 5: 'B-LOC',\n",
              " 6: 'I-LOC',\n",
              " 7: 'B-MISC',\n",
              " 8: 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLNbr51_JD_3",
        "outputId": "a36cb78e-cb90-4e49-a0d3-6d8607a2f149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-PER': 1,\n",
              " 'I-PER': 2,\n",
              " 'B-ORG': 3,\n",
              " 'I-ORG': 4,\n",
              " 'B-LOC': 5,\n",
              " 'I-LOC': 6,\n",
              " 'B-MISC': 7,\n",
              " 'I-MISC': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "87809e8836ef442bb108456b69fa5222",
            "0141951849b74943ac7f94ede38878f1",
            "8c1d152b4604448c9c3d9ca4f1e5f986",
            "84bd7b96d39546bbb4011b50dd5d313d",
            "95f37327c9814b7ebf94ae8bea5717d3",
            "b1ce8682c5944780a447fb5e0ef099c5",
            "52d2aab516cc4cb6a0d8c7a0b40c4ea7",
            "8e6cdad136214e048bdd16cc7b978585",
            "5306b53bbca64c288b8dc542a3b0913b",
            "a1180122d3fc4cbebbab80814ed45a64",
            "386b3fb909b947dfbbfff54b08fe254e"
          ]
        },
        "id": "qcMDPbJIUdTg",
        "outputId": "03caf44f-7ea2-4875-848e-51946fa0c5b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87809e8836ef442bb108456b69fa5222"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForTokenClassification\n",
        "\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ComeXUGzUfil"
      },
      "outputs": [],
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
        "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
        "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
        "num_epochs = 1\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=2e-5,\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQfBRumeJ6RD",
        "outputId": "60d3cc5c-752a-4318-8bb2-218bb7a10a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.optimization_tf.AdamWeightDecay at 0x79192a16f4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjmVIgN8Uq0m",
        "outputId": "a356ea21-b422-4993-8d85-0e3dbda868d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "878/878 [==============================] - 167s 150ms/step - loss: 0.1901 - val_loss: 0.0707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c82d5a6b1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# from transformers.keras_callbacks import PushToHubCallback\n",
        "\n",
        "# callback = PushToHubCallback(output_dir=\"bert-finetuned-ner\", tokenizer=tokenizer)\n",
        "\n",
        "# model.fit(\n",
        "#     tf_train_dataset,\n",
        "#     validation_data=tf_eval_dataset,\n",
        "#     # callbacks=[callback],\n",
        "#     epochs=num_epochs,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained('/content/drive/MyDrive/NER_Bert')\n"
      ],
      "metadata": {
        "id": "UEgaBRx303Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_weights('/content/drive/MyDrive/NER_Bert')\n"
      ],
      "metadata": {
        "id": "WwKB16jp4_FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForTokenClassification\n",
        "model = TFAutoModelForTokenClassification.from_pretrained('/content/drive/MyDrive/NER_Bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GirMBcF44sn5",
        "outputId": "09c841b1-8026-4646-9f97-ff4c28eae44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/NER_Bert were not used when initializing TFBertForTokenClassification: ['dropout_151']\n",
            "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at /content/drive/MyDrive/NER_Bert.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoL9CFtfU2S7"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6o8nsWAVBFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c6db18-9bc1-4bf3-81ab-9d684b135db1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "labels = [label_names[i] for i in labels]\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SklAwebSVYYr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPt2yrfsVBYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c501fb50-9bf8-4301-9725-12b365ff7029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0,\n",
              "  'recall': 0.5,\n",
              "  'f1': 0.6666666666666666,\n",
              "  'number': 2},\n",
              " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 0.6666666666666666,\n",
              " 'overall_f1': 0.8,\n",
              " 'overall_accuracy': 0.8888888888888888}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaCPviPCVdPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56261350-4b6a-429c-e64a-44e45fd9f9cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fwWq6u5Vfws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f386a8-8727-4968-842f-07a096bb5a09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset"
      ],
      "metadata": {
        "id": "aE-PpFQ3Ycon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea36ca9b-0d22-49a0-c5e1-10aca1799efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec={'input_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tf_train_dataset)"
      ],
      "metadata": {
        "id": "XuH8DiINYhRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6486d18b-978a-4bb1-da9a-eee866a21e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "878"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_eval_dataset"
      ],
      "metadata": {
        "id": "4HOHEQwYYT3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ebc99b-b32d-456f-88e6-cb11896fb08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec={'input_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tf_eval_dataset)"
      ],
      "metadata": {
        "id": "9Sj7OwiSYnaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f07c4a-4ddb-4342-ad2b-7b23a92ee59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tf_eval_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "id": "Ip3JOqCkYvwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99f6c70-3aee-48ef-bf17-37c311f502a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[  101, 15531,  9741, 22441,  1942,   118,   149, 27514, 10954,\n",
            "         9272,  9637,  1708,  3048, 18172,  2036,   157,  1592, 22441,\n",
            "          152, 17145,  2069, 13020, 16972,  2101,   138, 26321,  9637,\n",
            "        15969, 27451, 11780,  1708,  7118, 16647,  9565,  3663,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   149, 11414,  2137, 11414,  1820,   118,  4775,   118,\n",
            "         1476,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1537,  1890,  1155,   118,  1668,  1200,  5676, 14068,\n",
            "         1261,  1300,  1111,  3383,  1113,  5286,  1112, 21854,  3222,\n",
            "         8860,  1118,  1126,  6687,  1105,  3614,  2326,  1107,  1160,\n",
            "         1552,  1106,  1321,  1166,  1120,  1103,  1246,  1104,  1103,\n",
            "         2514,  2899,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  2397,  2215,  1113,  1499,   117,  1463,   117,  1336,\n",
            "         1129,  1603,   118,  2077,  1112,  1641,  9521,  8493,   117,\n",
            "        15964,  1105,  9757,  1155,  1804,  1107,  1113,  2681,  1229,\n",
            "         5327,  1189,  1146,  1111,  1575,  1159,  1107,  1147,  4458,\n",
            "          118,  4634,  1801,  1222, 21942,   119,   102,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1258, 11518,  8860,  1149,  1111,  6032,  1113,  1103,\n",
            "         2280,  2106,  1120,  4378,  1914,   117, 21854,  2925,  1147,\n",
            "         1148,  6687,  1118,  5706,  2326,  1196,  1217, 21663,  1149,\n",
            "         1111,  1853,  1545,  1114,  1652,  6187,  2881,  4827,   140,\n",
            "         3556, 25699,  1781,  1210,  1111,  6032,   119,   102,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  6938,  1158,  1118, 21640,   117,  8860,  1400,   170,\n",
            "         4600,  1838,  1106,  1147,  1248,  6687,  1196, 14068,  2843,\n",
            "         1107,  1106, 15119,  1172,  1149,  1111, 21223,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  8493,   117,  1649,   117,  1440,  2218,  1106, 12699,\n",
            "         1147,  1499,  3205,  1170, 11896, 14607, 21984,  1105,  1943,\n",
            "         5723,  1522,  1172,   170,  3016,  5688,  1113,  1147,  1801,\n",
            "         1222,  6426,  1120,  3763,  1158,  1926,   119,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 21984,   117,  1737, 17317,  1106,  1652,   112,   188,\n",
            "         1141,   118,  1285,  5420,   117,  4168, 18960,   117,  1117,\n",
            "         1148,  2899,  1432,  1104,  1103,  1265,   117,  1112,  8493,\n",
            "         1680,  3413,  1477,  1105,  1261,   170,  1148,  6687,  1730,\n",
            "         1104,  5787,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1650,  1103,  1601,  6426,  1125,  1454,  1115,  1154,\n",
            "          170,  3413,   118,  1576,  4316,  1133,  1228,   118,  6898,\n",
            "         2511,  5723,  1125,   188, 12734, 16271,  1147,  7816,   117,\n",
            "         1781,  1300,  1111,  1572,  1107,  3615,  7318,  1105,  2128,\n",
            "         1172,  5205,  1113, 13606,  1111,  1421,  1105, 16252,  1111,\n",
            "         4458,   119,   102],\n",
            "       [  101,  1335,  1103, 16103,   117,  9757,  3495,  2929,  3726,\n",
            "          117,  1330,  1299, 14632,  1118,  1652,   117,  1598,  1106,\n",
            "         3747,  1117,  4217,  1112,  1119,  1723,  1117,  1300,  1111,\n",
            "         2532,  1113,  9170,  1114,  2908,  1136,  1149,  1113,  5286,\n",
            "         1107,  1103,  1801,  1222, 19876,   119,   102,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1124,  1108,  1218,  5534,  1118,  1652, 19953,  2392,\n",
            "        25991,  1150,  1189,  3102,  1112,  9757,  1804,  1113,  3565,\n",
            "         1580,  1111,  1978,   117,   170,  1730,  1104, 24354,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 15964,  2023,  1146,  1103,  8263,  1111,  1147,  1148,\n",
            "         2899,  1641,  1290,  3419,  1118,  7914, 22067,  1106, 15118,\n",
            "         1111,  1421,  1107,  1147,  1248,  6687,   117,  1253,  1620,\n",
            "         2326,  1283,  1121, 10101,  1126,  6687,  3326,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1925,  2545, 17820,  1261,  1565,  1111,  5787,  1133,\n",
            "         2929,  5234,   117, 13414,   117,  1105,  4446,   152,   112,\n",
            "         3414,  7990,   117, 11523,   117,  1261, 15964,  1106,  3862,\n",
            "         1475,  1105,   170,  1148,  6687,  1730,  1104, 24482,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1258,  1103,  9074,  1104,  3195,  1103,  2280,  1285,\n",
            "         1104,  1147,  1801,  6118,  4634,  1118,  1103,  4250,   117,\n",
            "         5327,  2843,  1146,   170,  6990,  1106, 21728, 21942,  1111,\n",
            "        21692,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1220,  1127,  1316,  1146,  1118,   170,   176,  7729,\n",
            "         2340,  5731,  1121,  1795,  2921,  1133,  4252,   118,  1652,\n",
            "         2698, 17124,  2405,   150,  1665,  1658, 26169,  1261,  1300,\n",
            "         1111,  3731,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1650,   188,  8928,  3491,  5327,  1125,  1680, 10601,\n",
            "         1111,  1210,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]])>, 'labels': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[-100,    0,    0,    0,    0,    0,    3,    4,    4,    4,    4,\n",
            "           4,    4,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    7,    8,    0,    0,    0,    0,    1,    2,    0,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    3,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    3,    0,    3,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    5,    6,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    5,    0,\n",
            "           0,    1,    2,    2,    2,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    3,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    2,    2,    0,    1,    2,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    3,    0,    5,    6,    6,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    1,    0,    0,    0,    0,    5,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100],\n",
            "       [-100,    0,    0,    5,    0,    3,    0,    1,    2,    0,    0,\n",
            "           0,    0,    0,    5,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    5,    0,    1,    2,    0,\n",
            "           0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    7,    1,    2,    0,    0,    0,    0,    0,    1,    2,\n",
            "           0,    0,    0,    0,    1,    2,    2,    2,    2,    0,    0,\n",
            "           0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0,    0,    0,\n",
            "           0,    0,    0,    3,    0,    0,    0, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    1,    2,    0,    7,    8,    8,    0,    0,    1,    2,\n",
            "           2,    2,    2,    0,    0,    0,    0,    0, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tf_eval_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkxi2fcm-Lhc",
        "outputId": "b917c96e-c8b5-4142-bd53-288e5c419639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[  101, 15531,  9741, 22441,  1942,   118,   149, 27514, 10954,\n",
            "         9272,  9637,  1708,  3048, 18172,  2036,   157,  1592, 22441,\n",
            "          152, 17145,  2069, 13020, 16972,  2101,   138, 26321,  9637,\n",
            "        15969, 27451, 11780,  1708,  7118, 16647,  9565,  3663,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,   149, 11414,  2137, 11414,  1820,   118,  4775,   118,\n",
            "         1476,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1537,  1890,  1155,   118,  1668,  1200,  5676, 14068,\n",
            "         1261,  1300,  1111,  3383,  1113,  5286,  1112, 21854,  3222,\n",
            "         8860,  1118,  1126,  6687,  1105,  3614,  2326,  1107,  1160,\n",
            "         1552,  1106,  1321,  1166,  1120,  1103,  1246,  1104,  1103,\n",
            "         2514,  2899,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  2397,  2215,  1113,  1499,   117,  1463,   117,  1336,\n",
            "         1129,  1603,   118,  2077,  1112,  1641,  9521,  8493,   117,\n",
            "        15964,  1105,  9757,  1155,  1804,  1107,  1113,  2681,  1229,\n",
            "         5327,  1189,  1146,  1111,  1575,  1159,  1107,  1147,  4458,\n",
            "          118,  4634,  1801,  1222, 21942,   119,   102,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1258, 11518,  8860,  1149,  1111,  6032,  1113,  1103,\n",
            "         2280,  2106,  1120,  4378,  1914,   117, 21854,  2925,  1147,\n",
            "         1148,  6687,  1118,  5706,  2326,  1196,  1217, 21663,  1149,\n",
            "         1111,  1853,  1545,  1114,  1652,  6187,  2881,  4827,   140,\n",
            "         3556, 25699,  1781,  1210,  1111,  6032,   119,   102,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  6938,  1158,  1118, 21640,   117,  8860,  1400,   170,\n",
            "         4600,  1838,  1106,  1147,  1248,  6687,  1196, 14068,  2843,\n",
            "         1107,  1106, 15119,  1172,  1149,  1111, 21223,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  8493,   117,  1649,   117,  1440,  2218,  1106, 12699,\n",
            "         1147,  1499,  3205,  1170, 11896, 14607, 21984,  1105,  1943,\n",
            "         5723,  1522,  1172,   170,  3016,  5688,  1113,  1147,  1801,\n",
            "         1222,  6426,  1120,  3763,  1158,  1926,   119,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 21984,   117,  1737, 17317,  1106,  1652,   112,   188,\n",
            "         1141,   118,  1285,  5420,   117,  4168, 18960,   117,  1117,\n",
            "         1148,  2899,  1432,  1104,  1103,  1265,   117,  1112,  8493,\n",
            "         1680,  3413,  1477,  1105,  1261,   170,  1148,  6687,  1730,\n",
            "         1104,  5787,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1650,  1103,  1601,  6426,  1125,  1454,  1115,  1154,\n",
            "          170,  3413,   118,  1576,  4316,  1133,  1228,   118,  6898,\n",
            "         2511,  5723,  1125,   188, 12734, 16271,  1147,  7816,   117,\n",
            "         1781,  1300,  1111,  1572,  1107,  3615,  7318,  1105,  2128,\n",
            "         1172,  5205,  1113, 13606,  1111,  1421,  1105, 16252,  1111,\n",
            "         4458,   119,   102],\n",
            "       [  101,  1335,  1103, 16103,   117,  9757,  3495,  2929,  3726,\n",
            "          117,  1330,  1299, 14632,  1118,  1652,   117,  1598,  1106,\n",
            "         3747,  1117,  4217,  1112,  1119,  1723,  1117,  1300,  1111,\n",
            "         2532,  1113,  9170,  1114,  2908,  1136,  1149,  1113,  5286,\n",
            "         1107,  1103,  1801,  1222, 19876,   119,   102,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1124,  1108,  1218,  5534,  1118,  1652, 19953,  2392,\n",
            "        25991,  1150,  1189,  3102,  1112,  9757,  1804,  1113,  3565,\n",
            "         1580,  1111,  1978,   117,   170,  1730,  1104, 24354,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101, 15964,  2023,  1146,  1103,  8263,  1111,  1147,  1148,\n",
            "         2899,  1641,  1290,  3419,  1118,  7914, 22067,  1106, 15118,\n",
            "         1111,  1421,  1107,  1147,  1248,  6687,   117,  1253,  1620,\n",
            "         2326,  1283,  1121, 10101,  1126,  6687,  3326,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1925,  2545, 17820,  1261,  1565,  1111,  5787,  1133,\n",
            "         2929,  5234,   117, 13414,   117,  1105,  4446,   152,   112,\n",
            "         3414,  7990,   117, 11523,   117,  1261, 15964,  1106,  3862,\n",
            "         1475,  1105,   170,  1148,  6687,  1730,  1104, 24482,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1258,  1103,  9074,  1104,  3195,  1103,  2280,  1285,\n",
            "         1104,  1147,  1801,  6118,  4634,  1118,  1103,  4250,   117,\n",
            "         5327,  2843,  1146,   170,  6990,  1106, 21728, 21942,  1111,\n",
            "        21692,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1220,  1127,  1316,  1146,  1118,   170,   176,  7729,\n",
            "         2340,  5731,  1121,  1795,  2921,  1133,  4252,   118,  1652,\n",
            "         2698, 17124,  2405,   150,  1665,  1658, 26169,  1261,  1300,\n",
            "         1111,  3731,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1650,   188,  8928,  3491,  5327,  1125,  1680, 10601,\n",
            "         1111,  1210,   119,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]])>, 'labels': <tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
            "array([[-100,    0,    0,    0,    0,    0,    3,    4,    4,    4,    4,\n",
            "           4,    4,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    7,    8,    0,    0,    0,    0,    1,    2,    0,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    3,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    3,    0,    3,    0,\n",
            "           0,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    5,    6,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    5,    0,\n",
            "           0,    1,    2,    2,    2,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    3,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    2,    2,    0,    1,    2,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    3,    0,    5,    6,    6,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    1,    0,    0,    0,    0,    5,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100],\n",
            "       [-100,    0,    0,    5,    0,    3,    0,    1,    2,    0,    0,\n",
            "           0,    0,    0,    5,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    5,    0,    1,    2,    0,\n",
            "           0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    7,    1,    2,    0,    0,    0,    0,    0,    1,    2,\n",
            "           0,    0,    0,    0,    1,    2,    2,    2,    2,    0,    0,\n",
            "           0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    0,    0,    0,\n",
            "           0,    0,    0,    3,    0,    0,    0, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    1,    2,    0,    7,    8,    8,    0,    0,    1,    2,\n",
            "           2,    2,    2,    0,    0,    0,    0,    0, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.predict_on_batch(batch)['logits']\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQDrtIkC-41v",
        "outputId": "67fb119a-675e-4fda-8fac-5f07ddaa508e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 4.746  , -0.965  , -0.6777 , ..., -0.8057 , -0.1145 ,\n",
              "         -0.2905 ],\n",
              "        [ 6.848  , -0.9863 , -1.234  , ..., -1.203  , -0.4536 ,\n",
              "         -0.5415 ],\n",
              "        [ 6.543  , -1.348  , -0.3247 , ..., -0.7856 , -1.616  ,\n",
              "          0.4424 ],\n",
              "        ...,\n",
              "        [ 0.3215 ,  0.53   ,  0.1543 , ..., -0.4553 , -0.07117,\n",
              "         -0.1472 ],\n",
              "        [ 1.939  , -0.7183 ,  0.4077 , ...,  0.07635, -0.785  ,\n",
              "          0.4956 ],\n",
              "        [ 1.462  , -0.5083 , -0.2869 , ..., -0.02351, -0.2155 ,\n",
              "          0.09796]],\n",
              "\n",
              "       [[ 3.734  , -0.837  , -0.975  , ..., -0.628  ,  0.436  ,\n",
              "         -0.3157 ],\n",
              "        [-0.6924 , -0.2247 , -1.826  , ...,  0.568  , -0.1643 ,\n",
              "         -1.141  ],\n",
              "        [-1.161  , -1.792  ,  0.277  , ...,  6.668  , -1.125  ,\n",
              "         -0.3792 ],\n",
              "        ...,\n",
              "        [ 2.156  , -0.734  , -1.614  , ..., -0.3618 ,  0.2471 ,\n",
              "         -1.212  ],\n",
              "        [-0.791  , -0.3032 , -1.711  , ...,  1.093  , -0.3984 ,\n",
              "         -1.173  ],\n",
              "        [-0.8345 , -0.3613 , -1.683  , ...,  1.498  , -0.469  ,\n",
              "         -1.084  ]],\n",
              "\n",
              "       [[ 5.625  , -1.012  , -0.879  , ..., -1.164  ,  0.1167 ,\n",
              "         -0.742  ],\n",
              "        [-0.01464, -0.3577 , -2.326  , ..., -1.871  ,  5.12   ,\n",
              "         -0.1438 ],\n",
              "        [-0.607  , -1.747  , -0.4707 , ...,  0.954  ,  1.072  ,\n",
              "          5.1    ],\n",
              "        ...,\n",
              "        [ 3.242  , -0.3403 , -1.588  , ..., -1.924  ,  2.281  ,\n",
              "         -0.962  ],\n",
              "        [ 2.947  , -0.1777 , -2.066  , ..., -2.13   ,  2.373  ,\n",
              "         -1.14   ],\n",
              "        [ 7.555  , -0.701  , -1.509  , ..., -2.031  , -0.3198 ,\n",
              "         -1.093  ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 5.668  , -1.131  , -0.917  , ..., -1.152  ,  0.2283 ,\n",
              "         -0.7954 ],\n",
              "        [ 8.48   , -0.9985 , -1.21   , ..., -1.734  , -0.921  ,\n",
              "         -1.014  ],\n",
              "        [ 8.65   , -1.034  , -1.135  , ..., -1.737  , -1.164  ,\n",
              "         -0.9053 ],\n",
              "        ...,\n",
              "        [ 7.816  , -0.917  , -1.351  , ..., -1.663  , -0.565  ,\n",
              "         -0.674  ],\n",
              "        [ 6.44   , -0.6655 , -1.637  , ..., -1.876  , -0.275  ,\n",
              "         -0.978  ],\n",
              "        [ 7.133  , -0.962  , -1.672  , ..., -1.752  , -0.2274 ,\n",
              "         -0.778  ]],\n",
              "\n",
              "       [[ 4.43   , -1.163  , -0.7744 , ..., -0.8965 ,  0.6343 ,\n",
              "         -0.4539 ],\n",
              "        [ 7.36   , -0.6914 , -1.566  , ..., -2.059  , -0.882  ,\n",
              "         -1.045  ],\n",
              "        [ 8.38   , -0.8706 , -1.034  , ..., -1.828  , -1.192  ,\n",
              "         -0.9404 ],\n",
              "        ...,\n",
              "        [ 4.848  ,  0.0285 , -1.075  , ..., -1.887  ,  0.1202 ,\n",
              "         -0.61   ],\n",
              "        [ 4.246  , -0.3948 , -0.936  , ..., -1.633  ,  0.787  ,\n",
              "         -0.8687 ],\n",
              "        [ 3.781  , -0.5054 , -0.9614 , ..., -1.482  ,  1.177  ,\n",
              "         -0.9263 ]],\n",
              "\n",
              "       [[ 6.31   , -0.982  , -1.064  , ..., -1.417  , -0.3098 ,\n",
              "         -0.9272 ],\n",
              "        [ 7.75   , -0.6323 , -1.542  , ..., -1.695  , -0.6685 ,\n",
              "         -0.735  ],\n",
              "        [ 8.43   , -0.855  , -1.279  , ..., -2.006  , -1.055  ,\n",
              "         -0.997  ],\n",
              "        ...,\n",
              "        [ 5.684  , -0.6904 , -1.428  , ..., -1.524  , -0.1882 ,\n",
              "         -0.4995 ],\n",
              "        [ 5.94   , -0.8784 , -1.334  , ..., -1.419  , -0.3496 ,\n",
              "         -0.4507 ],\n",
              "        [ 5.883  , -0.75   , -1.446  , ..., -1.629  , -0.1329 ,\n",
              "         -0.571  ]]], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqTTSsFp_Xcd",
        "outputId": "07e4098c-789b-4d60-b6a3-361719205e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 48, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kJhKwoh_5Lo",
        "outputId": "2c2cc1be-663b-485d-aa89-7eb1e662d1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.746   , -0.965   , -0.6777  , -0.787   , -0.4543  , -1.571   ,\n",
              "        -0.8057  , -0.1145  , -0.2905  ],\n",
              "       [ 6.848   , -0.9863  , -1.234   , -0.645   , -0.565   , -1.486   ,\n",
              "        -1.203   , -0.4536  , -0.5415  ],\n",
              "       [ 6.543   , -1.348   , -0.3247  , -1.607   ,  0.0994  , -1.827   ,\n",
              "        -0.7856  , -1.616   ,  0.4424  ],\n",
              "       [ 6.523   , -1.302   , -0.423   , -1.5     , -0.00902 , -1.956   ,\n",
              "        -0.824   , -1.443   ,  0.269   ],\n",
              "       [ 6.555   , -1.629   , -0.583   , -1.532   , -0.0312  , -1.931   ,\n",
              "        -0.757   , -1.336   ,  0.456   ],\n",
              "       [ 6.164   , -0.5547  , -1.297   , -0.6934  , -1.265   , -1.404   ,\n",
              "        -1.953   , -0.3894  , -0.3042  ],\n",
              "       [ 0.9775  ,  2.365   , -1.336   ,  0.9463  , -2.03    ,  0.3535  ,\n",
              "        -1.675   ,  1.867   , -1.114   ],\n",
              "       [ 1.51    , -1.253   ,  1.613   , -2.29    , -0.1292  , -2.234   ,\n",
              "         1.214   , -1.285   ,  3.059   ],\n",
              "       [ 1.518   , -1.026   ,  2.004   , -2.377   ,  0.3345  , -1.78    ,\n",
              "         1.197   , -1.588   ,  2.21    ],\n",
              "       [ 0.08466 ,  0.1711  ,  1.897   , -1.588   ,  0.565   , -1.061   ,\n",
              "         0.4646  , -1.357   ,  0.464   ],\n",
              "       [ 0.8516  , -1.169   ,  3.111   , -2.764   ,  0.782   , -2.135   ,\n",
              "         0.9116  , -1.582   ,  1.157   ],\n",
              "       [ 0.506   , -0.396   ,  2.783   , -2.299   ,  0.5884  , -1.719   ,\n",
              "         0.3604  , -1.777   ,  0.6772  ],\n",
              "       [ 0.456   , -1.5625  ,  3.283   , -2.775   ,  1.11    , -1.9795  ,\n",
              "         0.852   , -1.561   ,  0.569   ],\n",
              "       [ 1.228   , -1.463   ,  3.809   , -2.654   ,  1.419   , -2.426   ,\n",
              "         0.6753  , -2.027   ,  0.3997  ],\n",
              "       [ 2.168   , -1.609   ,  3.135   , -2.855   ,  1.217   , -2.184   ,\n",
              "         0.9604  , -2.088   ,  0.791   ],\n",
              "       [ 6.      , -0.781   , -0.4565  , -1.102   , -0.01013 , -1.909   ,\n",
              "        -1.237   , -1.184   , -0.1931  ],\n",
              "       [ 5.277   , -1.038   ,  0.1151  , -1.57    ,  0.2349  , -2.035   ,\n",
              "        -0.583   , -1.726   ,  0.3635  ],\n",
              "       [ 4.215   , -1.466   ,  0.6646  , -1.781   ,  0.6235  , -2.162   ,\n",
              "        -0.2266  , -1.617   ,  0.4663  ],\n",
              "       [ 4.656   , -0.4717  , -0.2308  , -1.046   , -0.412   , -1.75    ,\n",
              "        -1.096   , -0.807   , -0.2411  ],\n",
              "       [ 4.51    , -1.108   ,  0.983   , -1.686   ,  0.836   , -2.436   ,\n",
              "        -0.4795  , -1.73    ,  0.7456  ],\n",
              "       [ 4.31    , -1.612   ,  1.102   , -2.082   ,  0.7075  , -2.088   ,\n",
              "        -0.1558  , -1.906   ,  0.823   ],\n",
              "       [ 6.35    , -0.7476  , -0.8403  , -1.055   , -0.6704  , -1.631   ,\n",
              "        -1.633   , -0.769   ,  0.04553 ],\n",
              "       [ 2.965   ,  0.2053  , -1.534   ,  0.32    , -1.527   , -0.3618  ,\n",
              "        -2.16    ,  2.156   , -0.5576  ],\n",
              "       [ 3.643   , -1.545   ,  0.4275  , -2.105   ,  0.3232  , -1.8955  ,\n",
              "        -0.1381  , -1.727   ,  2.824   ],\n",
              "       [ 4.875   , -1.907   , -0.624   , -1.453   ,  0.0464  , -1.681   ,\n",
              "        -0.836   , -0.67    ,  1.382   ],\n",
              "       [ 4.28    , -1.588   ,  0.4138  , -1.997   ,  0.4438  , -2.162   ,\n",
              "        -0.362   , -1.2705  ,  1.686   ],\n",
              "       [ 4.234   , -1.992   ,  0.925   , -2.293   ,  0.566   , -2.13    ,\n",
              "        -0.0945  , -1.507   ,  2.129   ],\n",
              "       [ 5.227   , -1.655   , -0.4304  , -1.801   ,  0.1025  , -1.82    ,\n",
              "        -0.6733  , -0.937   ,  1.662   ],\n",
              "       [ 5.508   , -1.667   , -0.353   , -1.867   ,  0.4617  , -1.89    ,\n",
              "        -0.607   , -1.373   ,  1.097   ],\n",
              "       [ 5.14    , -1.716   , -0.1804  , -1.879   ,  0.4888  , -1.998   ,\n",
              "        -0.7676  , -1.401   ,  1.617   ],\n",
              "       [ 4.93    , -1.906   ,  0.0658  , -2.205   ,  0.3599  , -2.217   ,\n",
              "        -0.778   , -1.661   ,  1.856   ],\n",
              "       [ 5.875   , -1.573   , -0.792   , -1.13    , -0.1932  , -2.057   ,\n",
              "        -1.262   , -0.4294  ,  0.8506  ],\n",
              "       [ 5.81    , -1.55    , -0.3616  , -1.791   ,  0.1907  , -2.23    ,\n",
              "        -0.828   , -1.381   ,  0.957   ],\n",
              "       [ 5.863   , -1.62    , -0.1129  , -1.722   ,  0.1918  , -2.217   ,\n",
              "        -0.4517  , -1.451   ,  0.6104  ],\n",
              "       [ 5.457   , -1.865   , -0.1711  , -1.866   ,  0.2273  , -2.102   ,\n",
              "        -0.3877  , -1.516   ,  1.088   ],\n",
              "       [ 7.043   , -1.277   , -0.9473  , -1.115   , -0.6533  , -1.773   ,\n",
              "        -1.241   , -1.082   , -0.3313  ],\n",
              "       [ 4.22    , -0.1584  , -0.04587 , -0.7646  , -0.2334  , -1.65    ,\n",
              "        -0.8076  ,  0.08466 , -0.13    ],\n",
              "       [ 2.945   , -0.4944  , -0.672   ,  0.03029 , -1.155   , -0.5664  ,\n",
              "        -0.639   ,  0.704   ,  0.1017  ],\n",
              "       [ 0.6606  ,  0.83    , -0.697   ,  0.4324  , -1.478   ,  0.2188  ,\n",
              "        -0.92    ,  1.465   , -0.1936  ],\n",
              "       [ 0.4473  ,  0.9375  , -0.616   ,  0.3481  , -1.293   ,  0.2778  ,\n",
              "        -0.853   ,  1.323   , -0.2478  ],\n",
              "       [ 0.3748  ,  0.9395  , -0.512   ,  0.295   , -1.183   ,  0.3352  ,\n",
              "        -0.8057  ,  1.201   , -0.3335  ],\n",
              "       [ 0.3535  ,  1.094   , -0.508   ,  0.3477  , -1.164   ,  0.4026  ,\n",
              "        -0.856   ,  1.016   , -0.5264  ],\n",
              "       [ 0.1929  ,  0.878   , -0.483   ,  0.2751  , -1.189   ,  0.2335  ,\n",
              "        -0.861   ,  0.963   , -0.4475  ],\n",
              "       [ 0.173   ,  0.4067  , -0.2257  , -0.1356  , -1.105   ,  0.02469 ,\n",
              "        -0.7217  ,  0.6543  , -0.1619  ],\n",
              "       [ 0.222   ,  0.1932  , -0.1625  , -0.007866, -0.971   ,  0.01084 ,\n",
              "        -0.678   ,  0.4321  , -0.2251  ],\n",
              "       [ 0.3215  ,  0.53    ,  0.1543  , -0.01884 , -0.627   , -0.3472  ,\n",
              "        -0.4553  , -0.07117 , -0.1472  ],\n",
              "       [ 1.939   , -0.7183  ,  0.4077  , -0.9307  , -0.0765  , -0.94    ,\n",
              "         0.07635 , -0.785   ,  0.4956  ],\n",
              "       [ 1.462   , -0.5083  , -0.2869  , -0.076   , -0.3293  , -0.543   ,\n",
              "        -0.02351 , -0.2155  ,  0.09796 ]], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sctsBa2K_xQP",
        "outputId": "19ec6af8-7fc8-4d19-d162-8f1d30ad29df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = batch[\"labels\"]\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFZfBWun_gXj",
        "outputId": "3eb86709-72e0-4e7d-84a4-a26cc12ae6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 48), dtype=int64, numpy=\n",
              "array([[-100,    0,    0,    0,    0,    0,    3,    4,    4,    4,    4,\n",
              "           4,    4,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    7,    8,    0,    0,    0,    0,    1,    2,    0,    0,\n",
              "           0,    0,    0,    0,    0,    3,    0,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    3,    0,    3,    0,    3,    0,\n",
              "           0,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    5,    6,    0,    3,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    5,    0,\n",
              "           0,    1,    2,    2,    2,    0,    0,    0,    0,    0, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    0,    0,    3,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    1,    2,    2,    0,    1,    2,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    3,    0,    5,    6,    6,\n",
              "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    1,    0,    0,    0,    0,    5,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0, -100],\n",
              "       [-100,    0,    0,    5,    0,    3,    0,    1,    2,    0,    0,\n",
              "           0,    0,    0,    5,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    3,    0, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    0,    0,    5,    0,    1,    2,    0,\n",
              "           0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    7,    1,    2,    0,    0,    0,    0,    0,    1,    2,\n",
              "           0,    0,    0,    0,    1,    2,    2,    2,    2,    0,    0,\n",
              "           0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    3,    0,    0,    0,\n",
              "           0,    0,    0,    3,    0,    0,    0, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    1,    2,    0,    7,    8,    8,    0,    0,    1,    2,\n",
              "           2,    2,    2,    0,    0,    0,    0,    0, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100],\n",
              "       [-100,    0,    0,    0,    0,    3,    0,    0,    0,    0,    0,\n",
              "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100]])>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions = np.argmax(logits, axis=-1)"
      ],
      "metadata": {
        "id": "_UpywwAnAGDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdtagWbxAUm4",
        "outputId": "79ade2ff-c6b0-43b7-8c1f-a0aff87a9e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 1, 8, 8, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 1, 7, 7,\n",
              "        7, 1, 0, 0],\n",
              "       [0, 5, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 6, 6, 6, 6, 0,\n",
              "        0, 0, 0, 0, 0, 0, 5, 5, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 5, 5, 5],\n",
              "       [0, 7, 8, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7,\n",
              "        7, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0,\n",
              "        0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3,\n",
              "        3, 3, 0, 0],\n",
              "       [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 3, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0,\n",
              "        3, 3, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 3, 0, 5, 6, 6, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 2],\n",
              "       [0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "        1, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 5, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 5, 0, 1, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0,\n",
              "        0, 0, 0, 3],\n",
              "       [0, 7, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0,\n",
              "        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 1, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0,\n",
              "        0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 5, 0, 0, 1, 2,\n",
              "        2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0,\n",
              "        0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn7pAFnMALAG",
        "outputId": "9d35f84a-4388-48e0-828e-eca9cdfb101e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 48)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = []\n",
        "test_labels = []\n",
        "for prediction, label in zip(predictions, labels):\n",
        "  for predicted_idx, label_idx in zip(prediction, label):\n",
        "    if label_idx == -100:\n",
        "      continue\n",
        "    test_predictions.append(label_names[predicted_idx])\n",
        "    test_labels.append(label_names[label_idx])\n"
      ],
      "metadata": {
        "id": "PXNiXq-0HNdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXGW-9MaHnEY",
        "outputId": "5f0b3767-c041-4195-f9c8-3d39be0f9518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPtCgRWZIEL-",
        "outputId": "94bb8d41-3274-4b88-b178-aa7dca9862ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBAGJVslIJTb",
        "outputId": "b2982118-c05b-4d0c-c097-6d3d593c5607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0MsDKOjIO9p",
        "outputId": "eaed1576-eb52-48ec-d3b8-e79acbe70d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[test_predictions], references=[test_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BeXso0wISqF",
        "outputId": "5bff3718-d4f0-4300-ae6c-bf5195e1b45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_eval_dataset:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fe9bcPdAdP9",
        "outputId": "af61e245-1157-481c-a792-ad72ff88c6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'precision': 0.9180503481521157,\n",
              "  'recall': 0.9330430048992924,\n",
              "  'f1': 0.9254859611231101,\n",
              "  'number': 1837},\n",
              " 'MISC': {'precision': 0.7160377358490566,\n",
              "  'recall': 0.8232104121475055,\n",
              "  'f1': 0.7658930373360242,\n",
              "  'number': 922},\n",
              " 'ORG': {'precision': 0.8583877995642701,\n",
              "  'recall': 0.8814317673378076,\n",
              "  'f1': 0.8697571743929359,\n",
              "  'number': 1341},\n",
              " 'PER': {'precision': 0.9369791666666667,\n",
              "  'recall': 0.9766558089033659,\n",
              "  'f1': 0.9564061669324827,\n",
              "  'number': 1842},\n",
              " 'overall_precision': 0.8762853470437018,\n",
              " 'overall_recall': 0.9178727701110737,\n",
              " 'overall_f1': 0.8965970738122636,\n",
              " 'overall_accuracy': 0.9791899687996704}"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y6XtPVfIg0J",
        "outputId": "ee16f6a4-f074-4853-8d3d-cc413b3a8311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'I-MISC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'I-MISC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'I-MISC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'I-ORG',\n",
              " 'I-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-MISC',\n",
              " 'I-ORG',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTHqgZkoIoLk",
        "outputId": "af8b3f42-1265-430e-b578-d71dab386b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67948"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMEFWdL4Irad",
        "outputId": "c863ed3a-cd88-4357-8f42-3193259d2dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67948"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OXspK5iEVmZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Replace this with your own checkpoint\n",
        "model_checkpoint = \"/content/drive/MyDrive/NER_Bert\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")\n",
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0MPjfTjBCEp",
        "outputId": "2c7e4319-c748-41cf-ef56-6058a0d6d06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/NER_Bert were not used when initializing TFBertForTokenClassification: ['dropout_151']\n",
            "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at /content/drive/MyDrive/NER_Bert.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9850526,\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.67914295,\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9874817,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "N-_Hq8eP_-TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"My name is Muhlis cm and I am from india. I am a python Developer working at Turbolab Technologies\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSvKjQp-SC3a",
        "outputId": "0557ae9b-30ce-48df-c7ec-026a978e7cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Muhlis cm and I am from india. I am a python Developer working at Turbolab Technologies\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSr4wq3LWyq6",
        "outputId": "d838906d-5439-482e-fea8-1e39cdf19156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9125912,\n",
              "  'word': 'Muhlis cm',\n",
              "  'start': 11,\n",
              "  'end': 20},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.6270681,\n",
              "  'word': 'india',\n",
              "  'start': 35,\n",
              "  'end': 40},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9431938,\n",
              "  'word': 'Turbolab Technologies',\n",
              "  'start': 77,\n",
              "  'end': 98}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe0cc9630bfd4c9c9b0755859c6929fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22c7c48773f84b1a9a5383351292f233",
              "IPY_MODEL_e7efe94055464d50a6eb9de632135e33",
              "IPY_MODEL_25a1b05d8c01455d81c59bb5a18252fe"
            ],
            "layout": "IPY_MODEL_1d0b348c6c154443aec0920d755c816e"
          }
        },
        "22c7c48773f84b1a9a5383351292f233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e86680c8c4024c4aa97645033d5ef87d",
            "placeholder": "",
            "style": "IPY_MODEL_6d8e9fd4d90b4c90815ae1a5f4705451",
            "value": "Map: 100%"
          }
        },
        "e7efe94055464d50a6eb9de632135e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749be6a68f464b80849d1e7454d9944f",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6f47a3aaa3f4962b71c84ce1a85b268",
            "value": 3250
          }
        },
        "25a1b05d8c01455d81c59bb5a18252fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_793d69d97cf7455d8594e5294fd8b061",
            "placeholder": "",
            "style": "IPY_MODEL_93d2f84fc3e54ef58624870916f89f67",
            "value": " 3250/3250 [00:01&lt;00:00, 2312.83 examples/s]"
          }
        },
        "1d0b348c6c154443aec0920d755c816e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86680c8c4024c4aa97645033d5ef87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8e9fd4d90b4c90815ae1a5f4705451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "749be6a68f464b80849d1e7454d9944f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f47a3aaa3f4962b71c84ce1a85b268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "793d69d97cf7455d8594e5294fd8b061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d2f84fc3e54ef58624870916f89f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87809e8836ef442bb108456b69fa5222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0141951849b74943ac7f94ede38878f1",
              "IPY_MODEL_8c1d152b4604448c9c3d9ca4f1e5f986",
              "IPY_MODEL_84bd7b96d39546bbb4011b50dd5d313d"
            ],
            "layout": "IPY_MODEL_95f37327c9814b7ebf94ae8bea5717d3"
          }
        },
        "0141951849b74943ac7f94ede38878f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ce8682c5944780a447fb5e0ef099c5",
            "placeholder": "",
            "style": "IPY_MODEL_52d2aab516cc4cb6a0d8c7a0b40c4ea7",
            "value": "model.safetensors: 100%"
          }
        },
        "8c1d152b4604448c9c3d9ca4f1e5f986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6cdad136214e048bdd16cc7b978585",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5306b53bbca64c288b8dc542a3b0913b",
            "value": 435755784
          }
        },
        "84bd7b96d39546bbb4011b50dd5d313d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1180122d3fc4cbebbab80814ed45a64",
            "placeholder": "",
            "style": "IPY_MODEL_386b3fb909b947dfbbfff54b08fe254e",
            "value": " 436M/436M [00:06&lt;00:00, 112MB/s]"
          }
        },
        "95f37327c9814b7ebf94ae8bea5717d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ce8682c5944780a447fb5e0ef099c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d2aab516cc4cb6a0d8c7a0b40c4ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e6cdad136214e048bdd16cc7b978585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5306b53bbca64c288b8dc542a3b0913b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1180122d3fc4cbebbab80814ed45a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386b3fb909b947dfbbfff54b08fe254e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}